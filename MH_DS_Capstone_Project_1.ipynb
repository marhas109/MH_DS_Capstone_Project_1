{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Add a relevant banner image here](path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Short project description. Your bottom line up front (BLUF) insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Severity     Start_Lat     Start_Lng       End_Lat       End_Lng  \\\n",
      "count  7.728394e+06  7.728394e+06  7.728394e+06  4.325632e+06  4.325632e+06   \n",
      "mean   2.212384e+00  3.620119e+01 -9.470255e+01  3.626183e+01 -9.572557e+01   \n",
      "std    4.875313e-01  5.076079e+00  1.739176e+01  5.272905e+00  1.810793e+01   \n",
      "min    1.000000e+00  2.455480e+01 -1.246238e+02  2.456601e+01 -1.245457e+02   \n",
      "25%    2.000000e+00  3.339963e+01 -1.172194e+02  3.346207e+01 -1.177543e+02   \n",
      "50%    2.000000e+00  3.582397e+01 -8.776662e+01  3.618349e+01 -8.802789e+01   \n",
      "75%    2.000000e+00  4.008496e+01 -8.035368e+01  4.017892e+01 -8.024709e+01   \n",
      "max    4.000000e+00  4.900220e+01 -6.711317e+01  4.907500e+01 -6.710924e+01   \n",
      "\n",
      "       Distance(mi)  Temperature(F)  Wind_Chill(F)   Humidity(%)  \\\n",
      "count  7.728394e+06    7.564541e+06   5.729375e+06  7.554250e+06   \n",
      "mean   5.618423e-01    6.166329e+01   5.825105e+01  6.483104e+01   \n",
      "std    1.776811e+00    1.901365e+01   2.238983e+01  2.282097e+01   \n",
      "min    0.000000e+00   -8.900000e+01  -8.900000e+01  1.000000e+00   \n",
      "25%    0.000000e+00    4.900000e+01   4.300000e+01  4.800000e+01   \n",
      "50%    3.000000e-02    6.400000e+01   6.200000e+01  6.700000e+01   \n",
      "75%    4.640000e-01    7.600000e+01   7.500000e+01  8.400000e+01   \n",
      "max    4.417500e+02    2.070000e+02   2.070000e+02  1.000000e+02   \n",
      "\n",
      "       Pressure(in)  Visibility(mi)  Wind_Speed(mph)  Precipitation(in)  \n",
      "count  7.587715e+06    7.551296e+06     7.157161e+06       5.524808e+06  \n",
      "mean   2.953899e+01    9.090376e+00     7.685490e+00       8.407210e-03  \n",
      "std    1.006190e+00    2.688316e+00     5.424983e+00       1.102246e-01  \n",
      "min    0.000000e+00    0.000000e+00     0.000000e+00       0.000000e+00  \n",
      "25%    2.937000e+01    1.000000e+01     4.600000e+00       0.000000e+00  \n",
      "50%    2.986000e+01    1.000000e+01     7.000000e+00       0.000000e+00  \n",
      "75%    3.003000e+01    1.000000e+01     1.040000e+01       0.000000e+00  \n",
      "max    5.863000e+01    1.400000e+02     1.087000e+03       3.647000e+01  \n",
      "    ID   Source  Severity           Start_Time             End_Time  \\\n",
      "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
      "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
      "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
      "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
      "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
      "\n",
      "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
      "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
      "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
      "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
      "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
      "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
      "\n",
      "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
      "0   False  False           False          False        False          Night   \n",
      "1   False  False           False          False        False          Night   \n",
      "2   False  False           False           True        False          Night   \n",
      "3   False  False           False          False        False          Night   \n",
      "4   False  False           False           True        False            Day   \n",
      "\n",
      "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
      "0          Night             Night                 Night  \n",
      "1          Night             Night                   Day  \n",
      "2          Night               Day                   Day  \n",
      "3            Day               Day                   Day  \n",
      "4            Day               Day                   Day  \n",
      "\n",
      "[5 rows x 46 columns]\n",
      "Index(['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat',\n",
      "       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n",
      "       'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',\n",
      "       'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)',\n",
      "       'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction',\n",
      "       'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity',\n",
      "       'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n",
      "       'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n",
      "       'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
      "       'Astronomical_Twilight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_all_data = pd.read_csv('Data/US_Accidents_March23.csv')\n",
    "print(df_all_data.describe())\n",
    "print(df_all_data.head())\n",
    "print(df_all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_severity_by_state = pd.crosstab(df_all_data['Severity'], df_all_data['State'])\n",
    "df_severity_by_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart of accident severity by state\n",
    "states = df_severity_by_state.columns\n",
    "sev1 = df_severity_by_state.iloc[0]\n",
    "sev2 = df_severity_by_state.iloc[1]\n",
    "sev3 = df_severity_by_state.iloc[2]\n",
    "sev4 = ct_sev4_by_state = df_severity_by_state.iloc[3]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(states, sev1)\n",
    "plt.bar(states, sev2, bottom=sev1)\n",
    "plt.bar(states, sev3, bottom=sev1+sev2)\n",
    "plt.bar(states, sev4, bottom=sev1+sev2+sev3)\n",
    "plt.xlabel(\"State\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.legend([\"Severity 1\", \"Severity 2\", \"Severity 3\", \"Severity 4\"])\n",
    "plt.title(\"Accident Severity by State (2016 - 2023)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart of accident severity by state without sev2 (sev 2 >> than the others so obscures sev 1, 3, 4 above)\n",
    "states = df_severity_by_state.columns\n",
    "sev1 = df_severity_by_state.iloc[0]\n",
    "sev3 = df_severity_by_state.iloc[2]\n",
    "sev4 = ct_sev4_by_state = df_severity_by_state.iloc[3]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(states, sev1)\n",
    "plt.bar(states, sev3)\n",
    "plt.bar(states, sev4)\n",
    "plt.xlabel(\"State\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.legend([\"Severity 1\", \"Severity 3\", \"Severity 4\"])\n",
    "plt.title(\"Accident Severity by State, Excluding Severity 2 (2016 - 2023)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sev_by_crossing = pd.crosstab(df_all_data['Severity'], df_all_data['Crossing'])\n",
    "df_sev_by_crossing = df_sev_by_crossing.rename(columns={False: \"No\", True: \"Yes\"})\n",
    "df_sev_by_crossing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charts of accident severity by bump, traffic calming, roundabout\n",
    "# chart of accident severity by state\n",
    "crossing = df_sev_by_crossing.columns\n",
    "cr1 = df_sev_by_crossing.iloc[0]\n",
    "cr2 = df_sev_by_crossing.iloc[1]\n",
    "cr3 = df_sev_by_crossing.iloc[2]\n",
    "cr4 = df_sev_by_crossing.iloc[3]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(crossing, cr1)\n",
    "plt.bar(crossing, cr2)\n",
    "plt.bar(crossing, cr3)\n",
    "plt.bar(crossing, cr4)\n",
    "plt.xticks(rotation=60)\n",
    "plt.xlabel(\"Nearby Crossing\")\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.legend([\"Severity 1\", \"Severity 2\", \"Severity 3\", \"Severity 4\"])\n",
    "plt.title(\"Accident Severity by Proximity to Crossing, (2016 - 2023)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Count of Wind Direction Entries: {df_all_data['Wind_Direction'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection\n",
    "\n",
    "Based on my exploration of the data, I'm dropping the following fields from the dataset for the following reasons:\n",
    "\n",
    "- Source: contains information that has no relationship to causes and effects of accidents\n",
    "- Timezone: duplicates zip/state with less precision\n",
    "- Country: all data is from the United States so this field is redundant\n",
    "- Airport_Code: doesn't provide germane information-the exact location where weather conditions are reported is not a variable that can be adjusted\n",
    "- Weather_Timestamp: not related to the conditions of the accidents in any way\n",
    "- Wind_Direction: too many unique values; values are also not related to travel directions so it's unlikely they'll  produce clear/actionable conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Severity     Start_Lat     Start_Lng       End_Lat       End_Lng  \\\n",
      "count  7.728394e+06  7.728394e+06  7.728394e+06  4.325632e+06  4.325632e+06   \n",
      "mean   2.212384e+00  3.620119e+01 -9.470255e+01  3.626183e+01 -9.572557e+01   \n",
      "std    4.875313e-01  5.076079e+00  1.739176e+01  5.272905e+00  1.810793e+01   \n",
      "min    1.000000e+00  2.455480e+01 -1.246238e+02  2.456601e+01 -1.245457e+02   \n",
      "25%    2.000000e+00  3.339963e+01 -1.172194e+02  3.346207e+01 -1.177543e+02   \n",
      "50%    2.000000e+00  3.582397e+01 -8.776662e+01  3.618349e+01 -8.802789e+01   \n",
      "75%    2.000000e+00  4.008496e+01 -8.035368e+01  4.017892e+01 -8.024709e+01   \n",
      "max    4.000000e+00  4.900220e+01 -6.711317e+01  4.907500e+01 -6.710924e+01   \n",
      "\n",
      "       Distance(mi)  Temperature(F)  Wind_Chill(F)   Humidity(%)  \\\n",
      "count  7.728394e+06    7.564541e+06   5.729375e+06  7.554250e+06   \n",
      "mean   5.618423e-01    6.166329e+01   5.825105e+01  6.483104e+01   \n",
      "std    1.776811e+00    1.901365e+01   2.238983e+01  2.282097e+01   \n",
      "min    0.000000e+00   -8.900000e+01  -8.900000e+01  1.000000e+00   \n",
      "25%    0.000000e+00    4.900000e+01   4.300000e+01  4.800000e+01   \n",
      "50%    3.000000e-02    6.400000e+01   6.200000e+01  6.700000e+01   \n",
      "75%    4.640000e-01    7.600000e+01   7.500000e+01  8.400000e+01   \n",
      "max    4.417500e+02    2.070000e+02   2.070000e+02  1.000000e+02   \n",
      "\n",
      "       Pressure(in)  Visibility(mi)  Wind_Speed(mph)  Precipitation(in)  \n",
      "count  7.587715e+06    7.551296e+06     7.157161e+06       5.524808e+06  \n",
      "mean   2.953899e+01    9.090376e+00     7.685490e+00       8.407210e-03  \n",
      "std    1.006190e+00    2.688316e+00     5.424983e+00       1.102246e-01  \n",
      "min    0.000000e+00    0.000000e+00     0.000000e+00       0.000000e+00  \n",
      "25%    2.937000e+01    1.000000e+01     4.600000e+00       0.000000e+00  \n",
      "50%    2.986000e+01    1.000000e+01     7.000000e+00       0.000000e+00  \n",
      "75%    3.003000e+01    1.000000e+01     1.040000e+01       0.000000e+00  \n",
      "max    5.863000e+01    1.400000e+02     1.087000e+03       3.647000e+01  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 40 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   ID                     object \n",
      " 1   Severity               int64  \n",
      " 2   Start_Time             object \n",
      " 3   End_Time               object \n",
      " 4   Start_Lat              float64\n",
      " 5   Start_Lng              float64\n",
      " 6   End_Lat                float64\n",
      " 7   End_Lng                float64\n",
      " 8   Distance(mi)           float64\n",
      " 9   Description            object \n",
      " 10  Street                 object \n",
      " 11  City                   object \n",
      " 12  County                 object \n",
      " 13  State                  object \n",
      " 14  Zipcode                object \n",
      " 15  Temperature(F)         float64\n",
      " 16  Wind_Chill(F)          float64\n",
      " 17  Humidity(%)            float64\n",
      " 18  Pressure(in)           float64\n",
      " 19  Visibility(mi)         float64\n",
      " 20  Wind_Speed(mph)        float64\n",
      " 21  Precipitation(in)      float64\n",
      " 22  Weather_Condition      object \n",
      " 23  Amenity                bool   \n",
      " 24  Bump                   bool   \n",
      " 25  Crossing               bool   \n",
      " 26  Give_Way               bool   \n",
      " 27  Junction               bool   \n",
      " 28  No_Exit                bool   \n",
      " 29  Railway                bool   \n",
      " 30  Roundabout             bool   \n",
      " 31  Station                bool   \n",
      " 32  Stop                   bool   \n",
      " 33  Traffic_Calming        bool   \n",
      " 34  Traffic_Signal         bool   \n",
      " 35  Turning_Loop           bool   \n",
      " 36  Sunrise_Sunset         object \n",
      " 37  Civil_Twilight         object \n",
      " 38  Nautical_Twilight      object \n",
      " 39  Astronomical_Twilight  object \n",
      "dtypes: bool(13), float64(12), int64(1), object(14)\n",
      "memory usage: 1.6+ GB\n",
      "None\n",
      "Index(['ID', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng',\n",
      "       'End_Lat', 'End_Lng', 'Distance(mi)', 'Description', 'Street', 'City',\n",
      "       'County', 'State', 'Zipcode', 'Temperature(F)', 'Wind_Chill(F)',\n",
      "       'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)',\n",
      "       'Precipitation(in)', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
      "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
      "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
      "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
      "       'Astronomical_Twilight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_refined = df_all_data.drop(['Source', 'Timezone', 'Country', 'Airport_Code', 'Weather_Timestamp', 'Wind_Direction'], axis=1)\n",
    "\n",
    "print(df_refined.describe())\n",
    "print(df_refined.info())\n",
    "print(df_refined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined['Start_Time'] = pd.to_datetime(df_refined['Start_Time'], yearfirst=True, format='mixed')\n",
    "df_refined['End_Time'] = pd.to_datetime(df_refined['End_Time'], yearfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined['Acc_date'] = df_refined['Start_Time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined['End_Time'] = pd.to_datetime(df_refined['End_Time'], yearfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "      <th>Acc_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7728384</th>\n",
       "      <td>A-7777752</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 17:42:27</td>\n",
       "      <td>2019-08-23 18:11:10</td>\n",
       "      <td>34.064460</td>\n",
       "      <td>-118.003880</td>\n",
       "      <td>34.065330</td>\n",
       "      <td>-117.997150</td>\n",
       "      <td>0.390</td>\n",
       "      <td>At I-605 - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728385</th>\n",
       "      <td>A-7777753</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 17:40:12</td>\n",
       "      <td>2019-08-23 18:08:35</td>\n",
       "      <td>33.943599</td>\n",
       "      <td>-117.077880</td>\n",
       "      <td>33.943599</td>\n",
       "      <td>-117.077880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>At Jack Rabbit Trl - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728386</th>\n",
       "      <td>A-7777754</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 17:40:12</td>\n",
       "      <td>2019-08-23 18:08:35</td>\n",
       "      <td>34.261030</td>\n",
       "      <td>-119.228000</td>\n",
       "      <td>34.262390</td>\n",
       "      <td>-119.230870</td>\n",
       "      <td>0.189</td>\n",
       "      <td>At Telephone Rd/Exit 65 - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728387</th>\n",
       "      <td>A-7777755</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 17:43:56</td>\n",
       "      <td>2019-08-23 18:12:27</td>\n",
       "      <td>33.741700</td>\n",
       "      <td>-117.837090</td>\n",
       "      <td>33.739170</td>\n",
       "      <td>-117.830010</td>\n",
       "      <td>0.443</td>\n",
       "      <td>At CA-55 - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728388</th>\n",
       "      <td>A-7777756</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 18:30:23</td>\n",
       "      <td>2019-08-23 18:58:54</td>\n",
       "      <td>34.239104</td>\n",
       "      <td>-118.416176</td>\n",
       "      <td>34.239104</td>\n",
       "      <td>-118.416176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>At Osborne St/Exit 154 - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728389</th>\n",
       "      <td>A-7777757</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 18:03:25</td>\n",
       "      <td>2019-08-23 18:32:01</td>\n",
       "      <td>34.002480</td>\n",
       "      <td>-117.379360</td>\n",
       "      <td>33.998880</td>\n",
       "      <td>-117.370940</td>\n",
       "      <td>0.543</td>\n",
       "      <td>At Market St - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728390</th>\n",
       "      <td>A-7777758</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 19:11:30</td>\n",
       "      <td>2019-08-23 19:38:23</td>\n",
       "      <td>32.766960</td>\n",
       "      <td>-117.148060</td>\n",
       "      <td>32.765550</td>\n",
       "      <td>-117.153630</td>\n",
       "      <td>0.338</td>\n",
       "      <td>At Camino Del Rio/Mission Center Rd - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728391</th>\n",
       "      <td>A-7777759</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 19:00:21</td>\n",
       "      <td>2019-08-23 19:28:49</td>\n",
       "      <td>33.775450</td>\n",
       "      <td>-117.847790</td>\n",
       "      <td>33.777400</td>\n",
       "      <td>-117.857270</td>\n",
       "      <td>0.561</td>\n",
       "      <td>At Glassell St/Grand Ave - Accident. in the ri...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728392</th>\n",
       "      <td>A-7777760</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 19:00:21</td>\n",
       "      <td>2019-08-23 19:29:42</td>\n",
       "      <td>33.992460</td>\n",
       "      <td>-118.403020</td>\n",
       "      <td>33.983110</td>\n",
       "      <td>-118.395650</td>\n",
       "      <td>0.772</td>\n",
       "      <td>At CA-90/Marina Fwy/Jefferson Blvd - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728393</th>\n",
       "      <td>A-7777761</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-23 18:52:06</td>\n",
       "      <td>2019-08-23 19:21:31</td>\n",
       "      <td>34.133930</td>\n",
       "      <td>-117.230920</td>\n",
       "      <td>34.137360</td>\n",
       "      <td>-117.239340</td>\n",
       "      <td>0.537</td>\n",
       "      <td>At Highland Ave/Arden Ave - Accident.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019-08-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  Severity          Start_Time            End_Time  \\\n",
       "7728384  A-7777752         2 2019-08-23 17:42:27 2019-08-23 18:11:10   \n",
       "7728385  A-7777753         2 2019-08-23 17:40:12 2019-08-23 18:08:35   \n",
       "7728386  A-7777754         2 2019-08-23 17:40:12 2019-08-23 18:08:35   \n",
       "7728387  A-7777755         2 2019-08-23 17:43:56 2019-08-23 18:12:27   \n",
       "7728388  A-7777756         2 2019-08-23 18:30:23 2019-08-23 18:58:54   \n",
       "7728389  A-7777757         2 2019-08-23 18:03:25 2019-08-23 18:32:01   \n",
       "7728390  A-7777758         2 2019-08-23 19:11:30 2019-08-23 19:38:23   \n",
       "7728391  A-7777759         2 2019-08-23 19:00:21 2019-08-23 19:28:49   \n",
       "7728392  A-7777760         2 2019-08-23 19:00:21 2019-08-23 19:29:42   \n",
       "7728393  A-7777761         2 2019-08-23 18:52:06 2019-08-23 19:21:31   \n",
       "\n",
       "         Start_Lat   Start_Lng    End_Lat     End_Lng  Distance(mi)  \\\n",
       "7728384  34.064460 -118.003880  34.065330 -117.997150         0.390   \n",
       "7728385  33.943599 -117.077880  33.943599 -117.077880         0.000   \n",
       "7728386  34.261030 -119.228000  34.262390 -119.230870         0.189   \n",
       "7728387  33.741700 -117.837090  33.739170 -117.830010         0.443   \n",
       "7728388  34.239104 -118.416176  34.239104 -118.416176         0.000   \n",
       "7728389  34.002480 -117.379360  33.998880 -117.370940         0.543   \n",
       "7728390  32.766960 -117.148060  32.765550 -117.153630         0.338   \n",
       "7728391  33.775450 -117.847790  33.777400 -117.857270         0.561   \n",
       "7728392  33.992460 -118.403020  33.983110 -118.395650         0.772   \n",
       "7728393  34.133930 -117.230920  34.137360 -117.239340         0.537   \n",
       "\n",
       "                                               Description  ... Station  \\\n",
       "7728384                               At I-605 - Accident.  ...   False   \n",
       "7728385                     At Jack Rabbit Trl - Accident.  ...   False   \n",
       "7728386                At Telephone Rd/Exit 65 - Accident.  ...   False   \n",
       "7728387                               At CA-55 - Accident.  ...   False   \n",
       "7728388                 At Osborne St/Exit 154 - Accident.  ...   False   \n",
       "7728389                           At Market St - Accident.  ...   False   \n",
       "7728390    At Camino Del Rio/Mission Center Rd - Accident.  ...   False   \n",
       "7728391  At Glassell St/Grand Ave - Accident. in the ri...  ...   False   \n",
       "7728392     At CA-90/Marina Fwy/Jefferson Blvd - Accident.  ...   False   \n",
       "7728393              At Highland Ave/Arden Ave - Accident.  ...   False   \n",
       "\n",
       "          Stop Traffic_Calming Traffic_Signal Turning_Loop  Sunrise_Sunset  \\\n",
       "7728384  False           False          False        False             Day   \n",
       "7728385  False           False          False        False             Day   \n",
       "7728386  False           False          False        False             Day   \n",
       "7728387  False           False          False        False             Day   \n",
       "7728388  False           False          False        False             Day   \n",
       "7728389  False           False          False        False             Day   \n",
       "7728390  False           False          False        False             Day   \n",
       "7728391  False           False          False        False             Day   \n",
       "7728392  False           False          False        False             Day   \n",
       "7728393  False           False          False        False             Day   \n",
       "\n",
       "         Civil_Twilight  Nautical_Twilight  Astronomical_Twilight    Acc_date  \n",
       "7728384             Day                Day                    Day  2019-08-23  \n",
       "7728385             Day                Day                    Day  2019-08-23  \n",
       "7728386             Day                Day                    Day  2019-08-23  \n",
       "7728387             Day                Day                    Day  2019-08-23  \n",
       "7728388             Day                Day                    Day  2019-08-23  \n",
       "7728389             Day                Day                    Day  2019-08-23  \n",
       "7728390             Day                Day                    Day  2019-08-23  \n",
       "7728391             Day                Day                    Day  2019-08-23  \n",
       "7728392             Day                Day                    Day  2019-08-23  \n",
       "7728393             Day                Day                    Day  2019-08-23  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refined.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: 158386 temperatures still missing after date-zip fill.\n",
      "Filling remaining with date-state mean.\n",
      "Warning: 7341 temperatures still missing after date-state fill.\n",
      "Filling remaining with overall mean as last resort.\n"
     ]
    }
   ],
   "source": [
    "# replacing NaN values in the temperature column\n",
    "\n",
    "def fill_missing_temperatures(df, date_col='Acc_date', zip_col='Zipcode', state_col='State', temp_col='Temperature(F)'):\n",
    "    \"\"\"\n",
    "    Replaces NaN Temperature values with the mean temperature of entries\n",
    "    with the same date and zip code. If no match exists with date and county,\n",
    "    uses date and state.\n",
    "    \"\"\"\n",
    "    # Step 1: mean temperature for each date-zip combination\n",
    "    df_temp_fill = df_refined.copy()\n",
    "    \n",
    "    temp_means_zip = df_temp_fill.groupby([date_col, zip_col])[temp_col].transform('mean')\n",
    "    \n",
    "    # fill NaN values with the date-zip group mean\n",
    "    df_temp_fill[temp_col] = df_temp_fill[temp_col].fillna(temp_means_zip)\n",
    "    \n",
    "    # Step 2: date-state combination for remaining NaNs\n",
    "    if df_temp_fill[temp_col].isna().any():\n",
    "        remaining = df_temp_fill[temp_col].isna().sum()\n",
    "        print(f\"Info: {remaining} temperatures still missing after date-zip fill.\")\n",
    "        print(\"Filling remaining with date-state mean.\")\n",
    "        \n",
    "        temp_means_state = df_temp_fill.groupby([date_col, state_col])[temp_col].transform('mean')\n",
    "        df_temp_fill[temp_col] = df_temp_fill[temp_col].fillna(temp_means_state)\n",
    "    \n",
    "    # Step 3: if any NaNs still remain, fill with overall mean as last resort\n",
    "    if df_temp_fill[temp_col].isna().any():\n",
    "        remaining = df_temp_fill[temp_col].isna().sum()\n",
    "        print(f\"Warning: {remaining} temperatures still missing after date-state fill.\")\n",
    "        print(\"Filling remaining with overall mean as last resort.\")\n",
    "        df_temp_fill[temp_col] = df_temp_fill[temp_col].fillna(df_temp_fill[temp_col].mean())\n",
    "    \n",
    "    return df_temp_fill\n",
    "\n",
    "df_temp_fill = fill_missing_temperatures(df_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_fill['Temperature(F)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refined['Temperature(F)'] = df_temp_fill['Temperature(F)']\n",
    "\n",
    "df_refined['Temperature(F)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: 1949795 wind chills still missing after date-zip fill.\n",
      "Filling remaining with date-state mean.\n",
      "Warning: 687931 wind chills still missing after date-state fill.\n",
      "Filling remaining with overall mean as last resort.\n"
     ]
    }
   ],
   "source": [
    "# replacing NaN values in the wind chill column\n",
    "\n",
    "def fill_missing_windchill(df, date_col='Acc_date', zip_col='Zipcode', state_col='State', windchill_col='Wind_Chill(F)'):\n",
    "    \"\"\"\n",
    "    Replaces NaN wind chill values with the mean wind chill of entries\n",
    "    with the same date and zip code. If no match exists with date and county,\n",
    "    uses date and state.\n",
    "    \"\"\"\n",
    "    # Step 1: mean temperature for each date-zip combination\n",
    "    df_windchill_fill = df_refined.copy()\n",
    "    \n",
    "    windchill_means_zip = df_windchill_fill.groupby([date_col, zip_col])[windchill_col].transform('mean')\n",
    "    \n",
    "    # fill NaN values with the date-zip group mean\n",
    "    df_windchill_fill[windchill_col] = df_windchill_fill[windchill_col].fillna(windchill_means_zip)\n",
    "    \n",
    "    # Step 2: date-state combination for remaining NaNs\n",
    "    if df_windchill_fill[windchill_col].isna().any():\n",
    "        remaining = df_windchill_fill[windchill_col].isna().sum()\n",
    "        print(f\"Info: {remaining} wind chills still missing after date-zip fill.\")\n",
    "        print(\"Filling remaining with date-state mean.\")\n",
    "        \n",
    "        windchill_means_state = df_windchill_fill.groupby([date_col, state_col])[windchill_col].transform('mean')\n",
    "        df_windchill_fill[windchill_col] = df_windchill_fill[windchill_col].fillna(windchill_means_state)\n",
    "    \n",
    "    # Step 3: if any NaNs still remain, fill with overall mean as last resort\n",
    "    if df_windchill_fill[windchill_col].isna().any():\n",
    "        remaining = df_windchill_fill[windchill_col].isna().sum()\n",
    "        print(f\"Warning: {remaining} wind chills still missing after date-state fill.\")\n",
    "        print(\"Filling remaining with overall mean as last resort.\")\n",
    "        df_windchill_fill[windchill_col] = df_windchill_fill[windchill_col].fillna(df_windchill_fill[windchill_col].mean())\n",
    "    \n",
    "    return df_windchill_fill\n",
    "\n",
    "df_windchill_fill = fill_missing_windchill(df_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_windchill_fill['Wind_Chill(F)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_refined['Wind_Chill(F)'] = df_windchill_fill['Wind_Chill(F)']\n",
    "\n",
    "df_refined['Wind_Chill(F)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 708. MiB for an array with shape (12, 7728394) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m         df_hum_fill[hum_col] \u001b[38;5;241m=\u001b[39m df_hum_fill[hum_col]\u001b[38;5;241m.\u001b[39mfillna(df_hum_fill[hum_col]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_hum_fill\n\u001b[1;32m---> 35\u001b[0m df_hum_fill \u001b[38;5;241m=\u001b[39m \u001b[43mfill_missing_hum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_refined\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m, in \u001b[0;36mfill_missing_hum\u001b[1;34m(df, date_col, zip_col, state_col, hum_col)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mReplaces NaN humidity values with the mean humidity of entries\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mwith the same date and zip code. If no match exists with date and county,\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03muses date and state.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: mean humidity for each date-zip combination\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_hum_fill \u001b[38;5;241m=\u001b[39m \u001b[43mdf_refined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m hum_means_zip \u001b[38;5;241m=\u001b[39m df_hum_fill\u001b[38;5;241m.\u001b[39mgroupby([date_col, zip_col])[hum_col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# fill NaN values with the date-zip group mean\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\pandas\\core\\generic.py:6452\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6342\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   6344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6345\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6346\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6450\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   6451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6452\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\pandas\\core\\internals\\managers.py:664\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    661\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 664\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1829\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1827\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1829\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1830\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2272\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2270\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2272\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2275\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32mc:\\Users\\markh\\.conda\\envs\\ai-environment\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2304\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2301\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2303\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2304\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2305\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2307\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 708. MiB for an array with shape (12, 7728394) and data type float64"
     ]
    }
   ],
   "source": [
    "# replacing NaN values in the humidity column\n",
    "\n",
    "def fill_missing_hum(df, date_col='Acc_date', zip_col='Zipcode', state_col='State', hum_col='Humidity(%)'):\n",
    "    \"\"\"\n",
    "    Replaces NaN humidity values with the mean humidity of entries\n",
    "    with the same date and zip code. If no match exists with date and county,\n",
    "    uses date and state.\n",
    "    \"\"\"\n",
    "    # Step 1: mean humidity for each date-zip combination\n",
    "    df_hum_fill = df_refined.copy()\n",
    "    \n",
    "    hum_means_zip = df_hum_fill.groupby([date_col, zip_col])[hum_col].transform('mean')\n",
    "    \n",
    "    # fill NaN values with the date-zip group mean\n",
    "    df_hum_fill[hum_col] = df_hum_fill[hum_col].fillna(hum_means_zip)\n",
    "    \n",
    "    # Step 2: date-state combination for remaining NaNs\n",
    "    if df_hum_fill[hum_col].isna().any():\n",
    "        remaining = df_hum_fill[hum_col].isna().sum()\n",
    "        print(f\"Info: {remaining} humidity entries still missing after date-zip fill.\")\n",
    "        print(\"Filling remaining with date-state mean.\")\n",
    "        \n",
    "        hum_means_state = df_hum_fill.groupby([date_col, state_col])[hum_col].transform('mean')\n",
    "        df_hum_fill[hum_col] = df_hum_fill[hum_col].fillna(hum_means_state)\n",
    "    \n",
    "    # Step 3: if any NaNs still remain, fill with overall mean as last resort\n",
    "    if df_hum_fill[hum_col].isna().any():\n",
    "        remaining = df_hum_fill[hum_col].isna().sum()\n",
    "        print(f\"Warning: {remaining} humidity entries still missing after date-state fill.\")\n",
    "        print(\"Filling remaining with overall mean as last resort.\")\n",
    "        df_hum_fill[hum_col] = df_hum_fill[hum_col].fillna(df_hum_fill[hum_col].mean())\n",
    "    \n",
    "    return df_hum_fill\n",
    "\n",
    "df_hum_fill = fill_missing_hum(df_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've managed missing values in the code blocks above. Here's a brief explanation of my approch to each column:\n",
    "\n",
    "- Temperature, Wind_Chill, Humidity, Pressure, Visibility, Wind_Speed: imputed based on the mean temp of other accident entries sharing the same day and zip code (or state if there are none in the zip code)\n",
    "- Precipitation: assumed NaN indicates no precipitation and replaced NaN with zero\n",
    "- Weather_Condition: consolidated entries from 144 to \n",
    "- Sunrise_Sunset: imputed based on\n",
    "- Civil_Twilight: imputed based on\n",
    "- Nautical_Twilight: imputed based on\n",
    "- Astronomical_Twilight: imputed based on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Count of Unique Weather Condition Entries: {df_all_data['Weather_Condition'].nunique()}\")\n",
    "df_refined['Weather_Condition'].value_counts().sort_values(ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Business Insight/Recommendation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insight/Recommendation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau Dashboard link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "Text here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
